{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "queries = [\"Image+to+Image+Translation\", \"GAN\", \"Image+Translation\", \"Deep+Learning\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c3ab8363844a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mqueries_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myears\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "queries_dict = {}\n",
    "\n",
    "\n",
    "for q in queries:\n",
    "\n",
    "    titles, years = [], []\n",
    "\n",
    "    for i in range(0, 500, 10):\n",
    "\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:97.0) Gecko/20100101 Firefox/97.0'}\n",
    "        url = f'https://scholar.google.com/scholar?hl=fr&q={q}&start={i}'\n",
    "        response=requests.get(url,headers=headers)\n",
    "        soup=BeautifulSoup(response.content,'lxml')\n",
    "\n",
    "        is_captcha_on_page = soup.find(\"input\", id=\"recaptcha-token\") is not None\n",
    "\n",
    "\n",
    "        if is_captcha_on_page:\n",
    "            print(\"CAPTCHA\")\n",
    "            break\n",
    "\n",
    "\n",
    "        for item in soup.select('[data-lid]'):\n",
    "            try:\n",
    "                print('----------------------------------------')\n",
    "                # print(item)\n",
    "                year = int(item.select('.gs_a')[0].get_text().split(\",\")[-1].split(\"-\")[0])\n",
    "                title = str(item.select('h3')[0].get_text())\n",
    "                print(\"title:\", title)\n",
    "                print(\"year: \", year)\n",
    "                years.append(years)\n",
    "                titles.append(title)\n",
    "            \n",
    "            except Exception as e:\n",
    "                #raise e\n",
    "                # print('')\n",
    "                pass\n",
    "        \n",
    "        queries_dict[q] = [titles, years]\n",
    "        time.sleep(2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n",
       "<html dir=\"LTR\">\n",
       "<head><meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/><meta content=\"initial-scale=1\" name=\"viewport\"/><title>https://scholar.google.com/scholar?hl=fr&amp;q=Image+to+Image+Translation&amp;start=10</title></head>\n",
       "<body onload=\"e=document.getElementById('captcha');if(e){e.focus();} if(solveSimpleChallenge) {solveSimpleChallenge(,);}\" style=\"font-family: arial, sans-serif; background-color: #fff; color: #000; padding:20px; font-size:18px;\">\n",
       "<div style=\"max-width:400px;\">\n",
       "<hr noshade=\"\" size=\"1\" style=\"color:#ccc; background-color:#ccc;\"/><br/>\n",
       "<div style=\"font-size:13px;\">\n",
       "Nos systèmes ont détecté un trafic exceptionnel sur votre réseau informatique. Veuillez renvoyer votre requête ultérieurement. <a href=\"#\" onclick=\"document.getElementById('infoDiv').style.display='block';\">Que s'est-il passé ?</a><br/><br/>\n",
       "<div id=\"infoDiv\" style=\"display:none; background-color:#eee; padding:10px; margin:0 0 15px 0; line-height:1.4em;\">\n",
       "Cette page s'affiche lorsque Google détecte automatiquement des requêtes émanant de votre réseau informatique qui semblent enfreindre les <a href=\"//www.google.com/policies/terms/\">Conditions d'utilisation</a>. Le blocage prendra fin peu après l'arrêt de ces requêtes.<br/><br/>Des applications malveillantes, un plug-in de navigateur ou un script qui envoie des requêtes automatiques peuvent être à l'origine de ce trafic. Si vous utilisez une connexion réseau partagée, demandez de l'aide à votre administrateur. Il est possible qu'un autre ordinateur utilisant la même adresse IP soit en cause. <a href=\"//support.google.com/websearch/answer/86640\">En savoir plus</a><br/><br/>Il est possible que cette page s'affiche si vous utilisez des termes avancés auxquels les robots ont recours ou si vous envoyez des requêtes très rapidement.\n",
       "\n",
       "</div><br/>\n",
       "Adresse IP : 2a01:cb11:921:2b00:b4b0:5bd0:5830:b47f<br/>Heure : 2022-10-25T18:15:31Z<br/>URL : https://scholar.google.com/scholar?hl=fr&amp;q=Image+to+Image+Translation&amp;start=10<br/>\n",
       "</div></div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Image+to+Image+Translation': [['Unsupervised image-to-image translation networks',\n",
       "   'Deep generative adversarial networks for image-to-image translation: A review',\n",
       "   'Multimodal unsupervised image-to-image translation',\n",
       "   'Toward multimodal image-to-image translation',\n",
       "   'Image to image translation for domain adaptation',\n",
       "   'Conditional image-to-image translation',\n",
       "   'Image-to-image translation: Methods and applications',\n",
       "   'Few-shot unsupervised image-to-image translation',\n",
       "   'Image-to-image translation with conditional adversarial networks',\n",
       "   'Dualgan: Unsupervised dual learning for image-to-image translation',\n",
       "   'Encoding in style: a stylegan encoder for image-to-image translation',\n",
       "   'Instagan: Instance-aware image-to-image translation',\n",
       "   'Contrastive learning for unpaired image-to-image translation',\n",
       "   'Diverse image-to-image translation via disentangled representations',\n",
       "   'Stargan: Unified generative adversarial networks for multi-domain image-to-image translation',\n",
       "   'Unsupervised attention-guided image-to-image translation',\n",
       "   'Rethinking the truly unsupervised image-to-image translation',\n",
       "   'Image-to-image translation for cross-domain disentanglement',\n",
       "   'Drit++: Diverse image-to-image translation via disentangled representations',\n",
       "   'Transgaga: Geometry-aware unsupervised image-to-image translation',\n",
       "   'Tsit: A simple and versatile framework for image-to-image translation',\n",
       "   'Dual contrastive learning for unsupervised image-to-image translation',\n",
       "   'Unsupervised image-to-image translation with generative adversarial networks',\n",
       "   'Reusing discriminators for encoding: Towards unsupervised image-to-image translation',\n",
       "   'Dunit: Detection-based unsupervised image-to-image translation',\n",
       "   'Overview of image-to-image translation by use of deep neural networks: denoising, super-resolution, modality conversion, and reconstruction in medical imaging',\n",
       "   'Relgan: Multi-domain image-to-image translation via relative attributes',\n",
       "   'Smit: Stochastic multi-label image-to-image translation',\n",
       "   'Travelgan: Image-to-image translation by transformation vector learning',\n",
       "   'Towards instance-level image-to-image translation',\n",
       "   'Unrestricted facial geometry reconstruction using image-to-image translation',\n",
       "   'Unpaired image-to-image translation using cycle-consistent adversarial networks',\n",
       "   'Guided image-to-image translation with bi-directional feature transformation',\n",
       "   'CoMoGAN: continuous model-guided image-to-image translation',\n",
       "   'Improving shape deformation in unsupervised image-to-image translation',\n",
       "   'Image-to-image translation via hierarchical style disentanglement',\n",
       "   '[HTML][HTML] MRI cross-modality image-to-image translation',\n",
       "   'Xgan: Unsupervised image-to-image translation for many-to-many mappings',\n",
       "   'Multi-mapping image-to-image translation via learning disentanglement',\n",
       "   'Unsupervised multi-modal image registration via geometry preserving image-to-image translation',\n",
       "   'Domain adaptive image-to-image translation',\n",
       "   'Spa-gan: Spatial attention gan for image-to-image translation',\n",
       "   'Semi-supervised learning for few-shot image-to-image translation',\n",
       "   'Generative adversarial networks for image-to-image translation on multi-contrast mr images-a comparison of cyclegan and unit',\n",
       "   'Tuigan: Learning versatile image-to-image translation with two unpaired images',\n",
       "   'Quality-aware unpaired image-to-image translation',\n",
       "   'Exemplar guided unsupervised image-to-image translation with semantic consistency',\n",
       "   'Harmonic unpaired image-to-image translation',\n",
       "   'Memory-guided unsupervised image-to-image translation',\n",
       "   'Asymmetric GAN for unpaired image-to-image translation',\n",
       "   'Attention-guided generative adversarial networks for unsupervised image-to-image translation',\n",
       "   'Unsupervised image-to-image translation with stacked cycle-consistent adversarial networks',\n",
       "   'Attentiongan: Unpaired image-to-image translation using attention-guided generative adversarial networks',\n",
       "   'Sem-GAN: semantically-consistent image-to-image translation',\n",
       "   'Learning fixed points in generative adversarial networks: From image-to-image translation to disease detection and localization',\n",
       "   'Robotic instrument segmentation with image-to-image translation',\n",
       "   'Transfer learning for related reinforcement learning tasks via image-to-image translation',\n",
       "   'FairfaceGAN: Fairness-aware facial image-to-image translation',\n",
       "   'Unpaired image-to-image translation using adversarial consistency loss',\n",
       "   'U-gat-it: Unsupervised generative attentional networks with adaptive layer-instance normalization for image-to-image translation',\n",
       "   'Art2real: Unfolding the reality of artworks via semantically-aware image-to-image translation',\n",
       "   'Unified generative adversarial networks for controllable image-to-image translation',\n",
       "   'Domain bridge for unpaired image-to-image translation and unsupervised domain adaptation',\n",
       "   'Ganhopper: Multi-hop gan for unsupervised image-to-image translation',\n",
       "   'Image-to-image translation via group-wise deep whitening-and-coloring transformation',\n",
       "   'Generating large labeled data sets for laparoscopic image processing tasks using unpaired image-to-image translation',\n",
       "   'Cross-domain car detection using unsupervised image-to-image translation: From day to night',\n",
       "   'Describe what to change: A text-guided unsupervised image-to-image translation approach',\n",
       "   'Homomorphic latent space interpolation for unpaired image-to-image translation',\n",
       "   'Discriminative region proposal adversarial networks for high-quality image-to-image translation',\n",
       "   'Dual generator generative adversarial networks for multi-domain image-to-image translation',\n",
       "   'Reversible gans for memory-efficient image-to-image translation',\n",
       "   'A novel framework for image-to-image translation and image compression',\n",
       "   'Unsupervised image-to-image translation using domain-specific variational information bound',\n",
       "   'In2i: Unsupervised multi-image-to-image translation using generative adversarial networks',\n",
       "   'Multimodal structure-consistent image-to-image translation',\n",
       "   'Transformation consistency regularization–a semi-supervised paradigm for image-to-image translation',\n",
       "   'Consistent embedded GAN for image-to-image translation',\n",
       "   'Image-to-image translation using generative adversarial network',\n",
       "   'Unsupervised image-to-image translation via pre-trained stylegan2 network',\n",
       "   'Segmentation guided image-to-image translation with adversarial networks',\n",
       "   'Multi-channel attention selection gans for guided image-to-image translation',\n",
       "   'Latent filter scaling for multimodal unsupervised image-to-image translation',\n",
       "   'Adversarial inverse graphics networks: Learning 2d-to-3d lifting and image-to-image translation from unpaired supervision',\n",
       "   'Probabilistic plant modeling via multi-view image-to-image translation',\n",
       "   'Underwater image dehazing via unpaired image-to-image translation',\n",
       "   'Image-to-image translation using a cross-domain auto-encoder and decoder',\n",
       "   'Singlegan: Image-to-image translation by a single-generator network using multiple generative adversarial learning',\n",
       "   'One-to-one Mapping for Unpaired Image-to-image Translation',\n",
       "   'Crossing-domain generative adversarial networks for unsupervised multi-domain image-to-image translation',\n",
       "   'Exploring explicit domain supervision for latent space disentanglement in unpaired image-to-image translation',\n",
       "   'Deceiving image-to-image translation networks for autonomous driving with adversarial perturbations',\n",
       "   'Model-based occlusion disentanglement for image-to-image translation',\n",
       "   'Semantically adaptive image-to-image translation for domain adaptation of semantic segmentation',\n",
       "   'Unsupervised image-to-image translation with self-attention networks',\n",
       "   'Learning image-to-image translation using paired and unpaired training samples',\n",
       "   'Zstgan: An adversarial approach for unsupervised zero-shot image-to-image translation',\n",
       "   'SemI2I: Semantically consistent image-to-image translation for domain adaptation of remote sensing data',\n",
       "   'Lc-gan: Image-to-image translation based on generative adversarial network for endoscopic images',\n",
       "   '[HTML][HTML] Generative reversible data hiding by image-to-image translation via GANs',\n",
       "   'Egsde: Unpaired image-to-image translation via energy-guided stochastic differential equations',\n",
       "   'Image-to-image translation using identical-pair adversarial networks',\n",
       "   'Multi-mapping image-to-image translation with central biasing normalization',\n",
       "   'Estimating the success of unsupervised image to image translation',\n",
       "   'Improving surgical training phantoms by hyperrealism: deep unpaired image-to-image translation from real surgeries',\n",
       "   '[PDF][PDF] Boosting segmentation with weak supervision from image-to-image translation',\n",
       "   'Image-to-image translation with multi-path consistency regularization',\n",
       "   'Cross domain adaptation for on-road object detection using multimodal structure-consistent image-to-image translation',\n",
       "   'Xogan: One-to-many unsupervised image-to-image translation',\n",
       "   'Gmm-unit: Unsupervised multi-domain and multi-modal image-to-image translation via attribute gaussian mixture modeling',\n",
       "   'Controlling biases and diversity in diverse image-to-image translation',\n",
       "   'Image-to-image translation with GAN for synthetic data augmentation in plant disease datasets',\n",
       "   '[PDF][PDF] Semantics-aware image to image translation and domain transfer',\n",
       "   'Efficient high-resolution image-to-image translation using multi-scale gradient u-net',\n",
       "   'Attribute guided unpaired image-to-image translation with semi-supervised learning',\n",
       "   '[HTML][HTML] Synthesis of COVID-19 chest X-rays using unpaired image-to-image translation',\n",
       "   'Unsupervised image-to-image translation via fair representation of gender bias',\n",
       "   'MedGAN: Medical image translation using GANs',\n",
       "   'SAR-to-optical image translation using supervised cycle-consistent adversarial networks',\n",
       "   'Deep networks for image-to-image translation with mux and demux layers',\n",
       "   'A pipeline for hand 2-D keypoint localization using unpaired image to image translation',\n",
       "   'Perceptual-DualGAN: perceptual losses for image to image translation with generative adversarial nets',\n",
       "   'Seamless nudity censorship: an image-to-image translation approach based on adversarial training',\n",
       "   '[CITATION][C] Semantically Consistent Image-to-Image Translation for Unsupervised Domain Adaptation.',\n",
       "   'Theoretical analysis of image-to-image translation with adversarial learning',\n",
       "   'Unit-ddpm: Unpaired image translation with denoising diffusion probabilistic models',\n",
       "   'Coco-funit: Few-shot unsupervised image translation with a content conditioned style encoder',\n",
       "   'Appearance generation for colored spun yarn fabric based on conditional image‐to‐image translation',\n",
       "   'Toward learning a unified many-to-many mapping for diverse image translation',\n",
       "   'Co-evolutionary compression for unpaired image translation',\n",
       "   'SDIT: Scalable and diverse cross-domain image translation',\n",
       "   'A unified feature disentangler for multi-domain image translation and manipulation',\n",
       "   'Unsupervised medical image translation using cycle-MedGAN',\n",
       "   'Spatially-adaptive pixelwise networks for fast image translation',\n",
       "   'Distilling portable generative adversarial networks for image translation',\n",
       "   'Multimodal image-to-image translation via a single generative adversarial network',\n",
       "   'Night-to-day image translation for retrieval-based localization',\n",
       "   'Unbalanced feature transport for exemplar-based image translation',\n",
       "   'Atrous cgan for sar to optical image translation',\n",
       "   'The spatially-correlative loss for various image translation tasks',\n",
       "   'High-resolution photorealistic image translation in real-time: A laplacian pyramid translation network',\n",
       "   'GANILLA: Generative adversarial networks for image to illustration translation',\n",
       "   'ResAttr-GAN: Unpaired deep residual attributes learning for multi-domain face image translation',\n",
       "   'Unsupervised multi-domain image translation with domain-specific encoders/decoders',\n",
       "   'Simplified unsupervised image translation for semantic segmentation adaptation',\n",
       "   'Cocosnet v2: Full-resolution correspondence learning for image translation',\n",
       "   'Augmenting colonoscopy using extended and directional cyclegan for lossy image translation',\n",
       "   'Font2Fonts: A modified Image-to-Image translation framework for font generation',\n",
       "   'Cross-domain medical image translation by shared latent Gaussian mixture model',\n",
       "   'Cross-domain interpolation for unpaired image-to-image translation',\n",
       "   'Unsupervised image translation using adversarial networks for improved plant disease recognition',\n",
       "   'Quantum image translation',\n",
       "   'Feature-guided SAR-to-optical image translation',\n",
       "   'Disrupting image-translation-based deepfake algorithms with adversarial attacks',\n",
       "   'Asymmetric CycleGan for unpaired NIR-to-RGB face image translation',\n",
       "   '[HTML][HTML] Sar-to-optical image translation based on conditional generative adversarial networks—Optimization, opportunities and limits',\n",
       "   'Cross-domain correspondence learning for exemplar-based image translation',\n",
       "   'Unsupervised image translation.',\n",
       "   'Towards annotation-efficient segmentation via image-to-image translation',\n",
       "   'Channel attention networks for image translation',\n",
       "   'Distribution matching losses can hallucinate features in medical image translation',\n",
       "   'Da-gan: Instance-level image translation by deep attention generative adversarial networks',\n",
       "   'Interactive sketch & fill: Multiclass sketch-to-image translation',\n",
       "   'Scientific discovery by generating counterfactuals using image translation',\n",
       "   'Deep learning thermal image translation for night vision perception',\n",
       "   'Unpaired Image Translation via Vector Symbolic Architectures',\n",
       "   'Deformation-aware unpaired image translation for pose estimation on laboratory animals',\n",
       "   'IR2VI: enhanced night environmental perception by unsupervised thermal image translation',\n",
       "   'Gan-based virtual-to-real image translation for urban scene semantic segmentation',\n",
       "   'Multi-component image translation for deep domain generalization',\n",
       "   '[HTML][HTML] Attention-aware discrimination for MR-to-CT image translation using cycle-consistent generative adversarial networks',\n",
       "   'Using out-of-the-box frameworks for contrastive unpaired image translation for vestibular schwannoma and cochlea segmentation: An approach for the crossmoda\\xa0…',\n",
       "   'Word level font-to-font image translation using convolutional recurrent generative adversarial networks',\n",
       "   'Vr facial animation via multiview image translation',\n",
       "   'Multi-channel attention selection gan with cascaded semantic guidance for cross-view image translation',\n",
       "   'Thermalgan: Multimodal color-to-thermal image translation for person re-identification in multispectral dataset',\n",
       "   'Bi-level feature alignment for versatile image translation and manipulation',\n",
       "   'A SAR-to-optical image translation method based on conditional generation adversarial network (cGAN)',\n",
       "   'A unified conditional disentanglement framework for multimodal brain mr image translation',\n",
       "   'Generative image translation for data augmentation of bone lesion pathology',\n",
       "   '[HTML][HTML] Generative image translation for data augmentation in colorectal histopathology images',\n",
       "   'Cross-domain object detection using unsupervised image translation',\n",
       "   'Combogan: Unrestrained scalability for image domain translation',\n",
       "   'Unsupervised video-to-video translation',\n",
       "   'Which way round? A study on the performance of stain-translation for segmenting arbitrarily dyed histological images',\n",
       "   'Mix and match networks: encoder-decoder alignment for zero-pair image translation',\n",
       "   'Show, attend, and translate: Unsupervised image translation with self-regularization and attention',\n",
       "   'Image-translation-based road marking extraction from mobile laser point clouds',\n",
       "   'Closing the loop: Joint rain generation and removal via disentangled image translation',\n",
       "   'Attribute-driven spontaneous motion in unpaired image translation',\n",
       "   'High-resolution daytime translation without domain labels',\n",
       "   'Disrupting deepfakes: Adversarial attacks against conditional image translation networks and facial manipulation systems',\n",
       "   'Source free domain adaptation with image translation',\n",
       "   'Autonomous driving in reality with reinforcement learning and image translation',\n",
       "   '[HTML][HTML] Data augmentation using image translation for underwater sonar image segmentation',\n",
       "   'Image translation for single-shot focal tomography',\n",
       "   '[CITATION][C] Mri image-to-image translation for cross-modality image registration and segmentation',\n",
       "   '[PDF][PDF] Learning landmarks from unaligned data using image translation',\n",
       "   'Thermal to visible facial image translation using generative adversarial networks',\n",
       "   'Gan-based unpaired chinese character image translation via skeleton transformation and stroke rendering',\n",
       "   'Improving the quality of synthetic FLAIR images with deep learning using a conditional generative adversarial network for pixel-by-pixel image translation',\n",
       "   'Data augmentation with symbolic-to-real image translation GANs for traffic sign recognition',\n",
       "   'Validating uncertainty in medical image translation',\n",
       "   'Unsupervised Medical Image Translation with Adversarial Diffusion Models',\n",
       "   'Superresolution digital image enhancement by subpixel image translation with a scanning micromirror',\n",
       "   '[CITATION][C] Unpaired image-to-image translation using cycle-consistent adversarial networks',\n",
       "   'Image translation between SAR and optical imagery with generative adversarial nets',\n",
       "   '[PDF][PDF] Multimodal Image Translation with Stochastic Style Representations and Mutual Information Loss.',\n",
       "   'Deep image translation with an affinity-based change prior for unsupervised multimodal change detection',\n",
       "   'AGTGAN: Unpaired Image Translation for Photographic Ancient Character Generation',\n",
       "   '[HTML][HTML] GAN meets chemometrics: Segmenting spectral images with pixel2pixel image translation with conditional generative adversarial networks',\n",
       "   'Alignment of cryo-EM movies of individual particles by optimization of image translations',\n",
       "   'Unpaired photo-to-caricature translation on faces in the wild',\n",
       "   'Mocycle-gan: Unpaired video-to-video translation',\n",
       "   'A crowdsourcing based mobile image translation and knowledge sharing service',\n",
       "   'Specular-to-diffuse translation for multi-view reconstruction',\n",
       "   'Dialectical GAN for SAR image translation: From Sentinel-1 to TerraSAR-X',\n",
       "   'Adversarial pulmonary pathology translation for pairwise chest X-ray data augmentation',\n",
       "   'Multi-density sketch-to-image translation network',\n",
       "   'HQA‐Trans: An end‐to‐end high‐quality‐awareness image translation framework for unsupervised cross‐domain pedestrian detection',\n",
       "   '[PDF][PDF] ESTHER: Extremely Simple Image Translation Through Self-Regularization.',\n",
       "   'Noise as domain shift: Denoising medical images by unpaired image translation',\n",
       "   'Controllable image-to-video translation: A case study on facial expression generation',\n",
       "   '[CITATION][C] Singh M Yang MH Ferrari V Hebert M Sminchisescu C Weiss Y Diverse image-to-image translation via disentangled representations',\n",
       "   'Semi few-shot attribute translation',\n",
       "   'Twin-GAN--unpaired cross-domain image translation with weight-sharing GANs',\n",
       "   '[CITATION][C] Image-to-image translation with conditional adversarial networks. arXiv preprint (2017)',\n",
       "   '[CITATION][C] Image-to-image translation with conditional adversarial networks (2016)',\n",
       "   'Uctgan: Diverse image inpainting based on unsupervised cross-space translation',\n",
       "   'Non-visual to visual translation for cross-domain face recognition',\n",
       "   '[CITATION][C] Unpaired image-to-image translation using cycle-consistent adversarial networks. CoRR abs/1703.10593 (2017)',\n",
       "   '[CITATION][C] Image-to-image translation with conditional adversarial networks. arXiv e-prints',\n",
       "   'Video-to-video translation with global temporal consistency',\n",
       "   '[CITATION][C] Image-to-image translation with conditional adversarial networks arXiv preprint',\n",
       "   '[CITATION][C] Unpaired image-to-image translation using cycle-consistent adversarial networks: arXiv preprint',\n",
       "   'T2net: Synthetic-to-realistic translation for solving single-image depth estimation tasks',\n",
       "   'Image translation between high-resolution remote sensing optical and SAR data using conditional GAN',\n",
       "   'Text-to-image-to-text translation using cycle consistent adversarial networks',\n",
       "   'Improved digital watermark robustness against translation and/or cropping of an image area',\n",
       "   'Guidance for horizontal image translation (HIT) of high definition stereoscopic video production',\n",
       "   'Towards realistic laparoscopic image generation using image-domain translation',\n",
       "   'Semantic translation of face image with limited pixels for simulated prosthetic vision',\n",
       "   'Enchanting your noodles: GAN-based real-time food-to-food translation and its impact on vision-induced gustatory manipulation',\n",
       "   'Progressive Domain Translation Defogging Network for Real-World Fog Images',\n",
       "   'Network-to-network translation with conditional invertible neural networks',\n",
       "   'Stereogan: Bridging synthetic-to-real domain gap by joint optimization of domain translation and stereo matching',\n",
       "   '[PDF][PDF] Cartoon-to-Photo Facial Translation with Generative Adversarial Networks.',\n",
       "   '[PDF][PDF] Adaptive Image Translation for Painterly Rendering.',\n",
       "   '[CITATION][C] Is image-to-image translation the panacea for multimodal image registration',\n",
       "   '[HTML][HTML] Improving unsupervised stain-to-stain translation using self-supervision and meta-learning',\n",
       "   'Pet image denoising using unsupervised domain translation',\n",
       "   'Structural analogy from a single image pair',\n",
       "   'The translation of shoeprint to barefoot footprint based on SM-GAN',\n",
       "   'Diagonal attention and style-based gan for content-style disentanglement in image generation and translation',\n",
       "   'Analysis of false data detection rate in generative adversarial networks using recurrent neural network',\n",
       "   'Gesturegan for hand gesture-to-gesture translation in the wild',\n",
       "   'A Dual-Generator Translation Network Fusing Texture and Structure Features for SAR and Optical Image Matching',\n",
       "   'Neural human video rendering by learning dynamic textures and rendering-to-video translation',\n",
       "   'Triple-translation GAN with multi-layer sparse representation for face image synthesis',\n",
       "   'DeepTaste: Augmented reality gustatory manipulation with GAN-based real-time food-to-food translation',\n",
       "   'Image-to-images translation for multi-task organ segmentation and bone suppression in chest x-ray radiography',\n",
       "   'Global and local translation designs of quantum image based on FRQI',\n",
       "   'Facial image-to-video translation by a hidden affine transformation',\n",
       "   'Deep cg2real: Synthetic-to-real translation via image disentanglement',\n",
       "   'All about structure: Adapting structural information across domains for boosting semantic segmentation',\n",
       "   '[CITATION][C] Efros Alexei A',\n",
       "   'Avid: Learning multi-stage tasks via pixel-level translation of human videos',\n",
       "   'Gesture-to-gesture translation in the wild via category-independent conditional maps',\n",
       "   '[CITATION][C] Alexei A, Efros',\n",
       "   'SHIFT: speedy histopathological-to-immunofluorescent translation of whole slide images using conditional generative adversarial networks',\n",
       "   'Davincigan: Unpaired surgical instrument translation for data augmentation',\n",
       "   'High-resolution image synthesis and semantic manipulation with conditional gans',\n",
       "   '[CITATION][C] PI, and AA Efros.“',\n",
       "   'Symmetric phase-only matched filtering of Fourier-Mellin transforms for image registration and recognition',\n",
       "   '[CITATION][C] Web image search by automatic image annotation and translation',\n",
       "   'Reciprocal translation between SAR and optical remote sensing images with cascaded-residual adversarial networks',\n",
       "   'Translation and scale invariants of Tchebichef moments',\n",
       "   'Computation of component image velocity from local phase information',\n",
       "   'Nir to rgb domain translation using asymmetric cycle generative adversarial networks',\n",
       "   'Image analysis via the general theory of moments',\n",
       "   'Cascade attention guided residue learning gan for cross-modal translation',\n",
       "   'Concept of constrained translation. Non-linguistic perspectives of translation',\n",
       "   'Carigans: Unpaired photo-to-caricature translation',\n",
       "   'M3D-GAN: Multi-modal multi-domain translation with universal attention',\n",
       "   'A deep translation (GAN) based change detection network for optical and SAR remote sensing images',\n",
       "   'Deep translation prior: Test-time training for photorealistic style transfer',\n",
       "   'Person transfer gan to bridge domain gap for person re-identification',\n",
       "   '[CITATION][C] Research',\n",
       "   'Automating tactile graphics translation',\n",
       "   '[HTML][HTML] projection-to-projection translation for Hybrid X-ray and Magnetic Resonance imaging',\n",
       "   'Learning to discover cross-domain relations with generative adversarial networks',\n",
       "   'Template matching using the parametric template vector with translation, rotation and scale invariance',\n",
       "   'The effectiveness of machine translation to improve the system of translating language on cultural context',\n",
       "   'Pix2pix-based stain-to-stain translation: A solution for robust stain normalization in histopathology images analysis',\n",
       "   'The translation sensitivity of wavelet-based registration',\n",
       "   '[CITATION][C] Image inpainting using multi-scale feature image translation',\n",
       "   'Multi-domain translation by learning uncoupled autoencoders',\n",
       "   '[CITATION][C] Autonomous driving in reality with reinforcement learning and image translation',\n",
       "   'BargainNet: Background-guided domain translation for image harmonization',\n",
       "   'Translation and scale invariants of Krawtchouk moments',\n",
       "   'An FFT-based technique for translation, rotation, and scale-invariant image registration',\n",
       "   '[CITATION][C] Deformation-aware unpaired image translation for pose estimation on laboratory animals. In 2020 IEEE',\n",
       "   '[CITATION][C] Face image translation based on self-discriminant cycle generation confrontation network',\n",
       "   'A Study of Fast Image Matching Method Under Translation, Scale and Rotation',\n",
       "   'Addressing challenging place recognition tasks using generative adversarial networks',\n",
       "   'Deblurgan: Blind motion deblurring using conditional adversarial networks',\n",
       "   'Preserving semantic and temporal consistency for unpaired video-to-video translation',\n",
       "   'Deep learning-based frozen section to FFPE translation',\n",
       "   'Echocardiography segmentation by quality translation using anatomically constrained cyclegan',\n",
       "   'Mri cross-modality neuroimage-to-neuroimage translation',\n",
       "   'Realistic endoscopic image generation method using virtual‐to‐real image‐domain translation',\n",
       "   'Translation camera',\n",
       "   '[HTML][HTML] Interactive echocardiography translation using few-shot GAN transfer learning',\n",
       "   'Towards cross-modal organ translation and segmentation: A cycle-and shape-consistent generative adversarial network',\n",
       "   'Cycada: Cycle-consistent adversarial domain adaptation',\n",
       "   'Rotation, scale and translation invariant digital image watermarking',\n",
       "   'Universal face photo-sketch style transfer via multiview domain translation',\n",
       "   'Vernier acuity during image rotation and translation: visual performance limits',\n",
       "   '[PDF][PDF] Real-time static Devnagri Sign Language translation using histogram',\n",
       "   'Cultural value of translation of proverbs and synopsis',\n",
       "   'Translation invariants of Zernike moments',\n",
       "   '[HTML][HTML] Real-time imaging of translation on single mRNA transcripts in live cells',\n",
       "   'A novel approach to image roto-translation estimation',\n",
       "   'Nonrigid motion correction in 3D using autofocusing withlocalized linear translations',\n",
       "   'Optimal unsupervised domain translation',\n",
       "   '[HTML][HTML] SHIFT: speedy histological-to-immunofluorescent translation of a tumor signature enabled by deep learning',\n",
       "   'Blind cross-spectral image registration using prefiltering and fourier-based translation detection',\n",
       "   'A universal music translation network',\n",
       "   'Face-to-parameter translation for game character auto-creation',\n",
       "   '[PDF][PDF] WP2-GAN: Wavelet-based Multi-level GAN for Progressive Facial Expression Translation with Parallel Generators',\n",
       "   'Image-to-voxel model translation with conditional adversarial networks',\n",
       "   'FSRM-STS: Cross-dataset pedestrian retrieval based on a four-stage retrieval model with Selection–Translation–Selection',\n",
       "   'Sign language production using neural machine translation and generative adversarial networks',\n",
       "   '[HTML][HTML] A survey on image data augmentation for deep learning',\n",
       "   'One-shot unsupervised cross domain translation',\n",
       "   'GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification',\n",
       "   'Visualization of single endogenous polysomes reveals the dynamics of translation in live human cells',\n",
       "   'Doubly attentive transformer machine translation',\n",
       "   'Generative adversarial networks: An overview',\n",
       "   '[PDF][PDF] Comparative study between wavelet thresholding techniques (hard, soft and invariant-translation) in ultrasound images',\n",
       "   'Invariant image recognition by Zernike moments',\n",
       "   'Automatic visual to tactile translation. i. human factors, access methods and image manipulation',\n",
       "   'Automatic image annotation and retrieval using cross-media relevance models',\n",
       "   'Rotation, scale, and translation resilient watermarking for images',\n",
       "   'Neural machine translation with universal visual representation',\n",
       "   'Mobile robot localization and mapping with uncertainty using scale-invariant visual landmarks',\n",
       "   'Face anti-spoofing via adversarial cross-modality translation',\n",
       "   'Translation, rotation and scale stabilisation of image sequences',\n",
       "   'Learning to transfer: Unsupervised meta domain translation',\n",
       "   'A coupling translation network for change detection in heterogeneous images',\n",
       "   'Aggregation via separation: Boosting facial landmark detector with semi-supervised style translation',\n",
       "   'Image-to-voxel model translation for 3d scene reconstruction and segmentation',\n",
       "   'A correlation-based approach to calculate rotation and translation of moving cells',\n",
       "   'Audio-visual speech translation with automatic lip syncqronization and face tracking based on 3-d head model',\n",
       "   'On image analysis by the methods of moments',\n",
       "   'Digital image correlation using Newton-Raphson method of partial differential correction',\n",
       "   '[HTML][HTML] Application of artificial intelligence in nuclear medicine and molecular imaging: a review of current status and future perspectives for clinical translation',\n",
       "   'Flexible, high performance convolutional neural networks for image classification',\n",
       "   \"Understanding rigid geometric transformations: Jeff's learning path for translation\",\n",
       "   'Responsible radiomics research for faster clinical translation',\n",
       "   'Unsupervised machine translation using monolingual corpora only',\n",
       "   'Latent translation: Crossing modalities by bridging generative models',\n",
       "   '[PDF][PDF] Cross-modal Bidirectional Translation via Reinforcement Learning.',\n",
       "   'Imitation from observation: Learning to imitate behaviors from raw video via context translation',\n",
       "   '[PDF][PDF] Object recognition as machine translation-part 2: Exploiting image data-base clustering models',\n",
       "   'Deep graph translation',\n",
       "   'Explicitly disentangling image content from translation and rotation with spatial-VAE',\n",
       "   '[PDF][PDF] Translation of Words with Cultural Image.',\n",
       "   'Multimodal pivots for image caption translation',\n",
       "   'DTT-Net: Dual-Domain Translation Transformer for Semi-Supervised Image Deraining',\n",
       "   'Translation insensitive image similarity in complex wavelet domain',\n",
       "   'Conditional adversarial domain adaptation',\n",
       "   'Translation-invariant contourlet transform and its application to image denoising',\n",
       "   'Translation of near-infrared fluorescence imaging technologies: emerging clinical applications',\n",
       "   'Semantic image synthesis with spatially-adaptive normalization',\n",
       "   'Cardiac point-of-care to cart-based ultrasound translation using constrained CycleGAN',\n",
       "   'A mobile application of American sign language translation via image processing algorithms',\n",
       "   '[HTML][HTML] Multi-domain translation between single-cell imaging and sequencing data using autoencoders',\n",
       "   'Color coding of digitized echocardiograms: description of a new technique and application in detecting and correcting for cardiac translation',\n",
       "   '[PDF][PDF] Text and image in translation',\n",
       "   'Computer visualization of three-dimensional image data using IMOD',\n",
       "   '[HTML][HTML] 3DFaceGAN: adversarial nets for 3D face representation, generation, and translation',\n",
       "   '[PDF][PDF] Multi-modal translation and evaluation of lip-synchronization using noise added voice',\n",
       "   '[PDF][PDF] A shared task on multimodal machine translation and crosslingual image description',\n",
       "   '[PDF][PDF] Binary translation',\n",
       "   'Supervised translation-invariant sparse coding',\n",
       "   'Triple-GAN: Progressive face aging with triple translation loss',\n",
       "   'Rotation, scale and translation invariant spread spectrum digital image watermarking',\n",
       "   'Affine reconstruction from perspective image pairs with a relative object-camera translation in between',\n",
       "   \"Middle-school students' concept images of geometric translations\",\n",
       "   'Anomaly detection for medical images using self-supervised and translation-consistent features',\n",
       "   'The UOB-telecom Paristech Arabic handwriting recognition and translation systems for the openhart 2013 competition',\n",
       "   '[HTML][HTML] Accelerated cryo-EM structure determination with parallelisation using GPUs in RELION-2',\n",
       "   'The rotator cuff opposes superior translation of the humeral head',\n",
       "   'Image retrieval using color and shape',\n",
       "   '80 million tiny images: A large data set for nonparametric object and scene recognition',\n",
       "   'Image-guided surgery using invisible near-infrared light: fundamentals of clinical translation',\n",
       "   'Object recognition as machine translation: Learning a lexicon for a fixed image vocabulary',\n",
       "   'Unsupervised multimodal neural machine translation with pseudo visual pivoting',\n",
       "   'Automated detection of diabetic retinopathy: barriers to translation into clinical practice',\n",
       "   'Rotation, scaling, translation invariant image watermarking based on radon transform',\n",
       "   'Translation-invariant denoising using multiwavelets',\n",
       "   'Skeleton based action recognition using translation-scale invariant image mapping and multi-scale deep CNN',\n",
       "   'Roto-translation covariant convolutional networks for medical image analysis',\n",
       "   'Data-to-Data and Gradient-to-Gradient Translations in Geophysics Using Deep Neural Networks',\n",
       "   'Almost translation invariant wavelet transformations for speckle reduction of SAR images',\n",
       "   'Development and clinical translation of photoacoustic mammography',\n",
       "   'Automated tactile graphics translation: in the field',\n",
       "   '[HTML][HTML] Compartmentalization of transcription and translation in Bacillus subtilis',\n",
       "   'Achieving human parity on automatic chinese to english news translation',\n",
       "   'Retinal imaging and image analysis',\n",
       "   'Scene text extraction and translation for handheld devices',\n",
       "   'elastix: A Toolbox for Intensity-Based Medical Image Registration',\n",
       "   'Image-based visual servo control of the translation kinematics of a quadrotor aerial vehicle',\n",
       "   'Endogenous convolutional sparse representations for translation invariant image subspace models',\n",
       "   'What is translation?',\n",
       "   'Review of shape representation and description techniques',\n",
       "   'Photobook: Tools for content-based manipulation of image databases',\n",
       "   'Fundamental limits of reconstruction-based superresolution algorithms under local translation',\n",
       "   'Optimal motion control for image-based visual servoing by decoupling translation and rotation',\n",
       "   '[HTML][HTML] Text2Sign: towards sign language production using neural machine translation and generative adversarial networks',\n",
       "   'Real-time Malaysian sign language translation using colour segmentation and neural network',\n",
       "   'Sign Language Translation',\n",
       "   'Rotation, scaling and translation invariant image watermarking using feature points',\n",
       "   'Painting completion with generative translation models',\n",
       "   'Batch-instance normalization for adaptively style-invariant neural networks',\n",
       "   \"What is 'translation'?\",\n",
       "   'Translation and validation of body image instruments: Challenges, good practice guidelines, and reporting recommendations for test adaptation',\n",
       "   'Translation-aware semantic segmentation via conditional least-square generative adversarial networks',\n",
       "   '3D skeleton based action recognition by video-domain translation-scale invariant mapping and multi-scale dilated CNN',\n",
       "   'Unsupervised multi-modal neural machine translation',\n",
       "   'Findings of the second shared task on multimodal machine translation and multilingual image description',\n",
       "   'Unsupervised dialectal neural machine translation',\n",
       "   'IMAGES OF TRANSLATION: Metaphor and Imagery in the Renai ssance Discourse on Translation',\n",
       "   'Reduction of eddy‐current‐induced distortion in diffusion MRI using a twice‐refocused spin echo',\n",
       "   'Reliable feature matching across widely separated views',\n",
       "   'A respiratory self‐gating technique with 3D‐translation compensation for free‐breathing whole‐heart coronary MRA',\n",
       "   'Robust rotation and translation estimation in multiview reconstruction',\n",
       "   'The plurisemiotics of pop song translation: Words, music, voice and image',\n",
       "   'Image analysis using mathematical morphology',\n",
       "   'Automatic visual to tactile translation. II. Evaluation of the TACTile image creation system',\n",
       "   'LaT: Latent Translation with Cycle-Consistency for Video-Text Retrieval',\n",
       "   'Application and translation of artificial intelligence to cardiovascular imaging in nuclear medicine and noncontrast CT',\n",
       "   'Feature extraction with an improved scale-invariants for deformation digits',\n",
       "   '[HTML][HTML] Modelling intra-muscular contraction dynamics using in silico to in vivo domain translation',\n",
       "   'Fine-tuning by curriculum learning for non-autoregressive neural machine translation',\n",
       "   'QIN benchmarks for clinical translation of quantitative imaging tools',\n",
       "   'Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks',\n",
       "   '[PDF][PDF] Lexical translation with application to image searching on the web',\n",
       "   'Show and tell: A neural image caption generator',\n",
       "   'Deep visual domain adaptation: A survey',\n",
       "   'Audiovisual translation comes of age',\n",
       "   'Does multimodality help human and machine for translation and image captioning?',\n",
       "   'Spatial normalization of brain images with focal lesions using cost function masking',\n",
       "   'Characterizing responses of translation-invariant neurons to natural stimuli: maximally informative invariant dimensions',\n",
       "   'M2m: Imbalanced classification via major-to-minor translation',\n",
       "   'Change in Translation and the Image of the Translator',\n",
       "   'Image matching for translation, rotation and uniform scaling by the radon transform',\n",
       "   '[PDF][PDF] Pyramidal implementation of the affine lucas kanade feature tracker description of the algorithm',\n",
       "   '[CITATION][C] The Translation Invariant Wavelet-based Contourlet Transform for Image Denoising.',\n",
       "   'The image of translation in science fiction & astronomy',\n",
       "   'Metaphor in translation',\n",
       "   \"Image matching as a diffusion process: an analogy with Maxwell's demons\",\n",
       "   '[PDF][PDF] Translation and Retrieval of Image Information to and from Sound',\n",
       "   '[HTML][HTML] Roto-translation equivariant convolutional networks: Application to histopathology image analysis',\n",
       "   '[PDF][PDF] Relevance and the translation of poetry',\n",
       "   'Watermarking resistance to translation, rotation, and scaling',\n",
       "   \"[PDF][PDF] Paratextual elements in translation: paratranslating titles in children's literature\",\n",
       "   'Development of a symmetric echo planar imaging framework for clinical translation of rapid dynamic hyperpolarized 13C imaging',\n",
       "   'Machine translation system as virtual appliance: for scalable service deployment on cloud',\n",
       "   'Cognitive approach to metaphor translation in literary discourse',\n",
       "   'Image-guided drug delivery: preclinical applications and clinical translation',\n",
       "   'Multimodal machine translation with reinforcement learning',\n",
       "   'The scanning mechanism of eukaryotic translation initiation',\n",
       "   'Pseudopolar-based estimation of large translations, rotations, and scalings in images',\n",
       "   '[PDF][PDF] English to Hindi multi modal image caption translation'],\n",
       "  [[...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...],\n",
       "   [...]]],\n",
       " 'GAN': [['GaN electronics',\n",
       "   'Ion implantation into GaN',\n",
       "   'Application-based review of GaN HFETs',\n",
       "   'Storygan: A sequential conditional gan for story visualization',\n",
       "   'Recurrent topic-transition gan for visual paragraph generation',\n",
       "   'From gan to wgan',\n",
       "   'GaN growth using GaN buffer layer',\n",
       "   'Polarization effects in AlGaN/GaN and GaN/AlGaN/GaN heterostructures',\n",
       "   'Sequential attention GAN for interactive image editing',\n",
       "   'Geometric gan'],\n",
       "  [[...], [...], [...], [...], [...], [...], [...], [...], [...], [...]]],\n",
       " 'Image+Translation': [[], []],\n",
       " 'Deep+Learning': [[], []]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(queries_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b50cb8e675b5ef77c9f891596a2e1e7a584ca67d36187c9271033bd2e1b1494a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
